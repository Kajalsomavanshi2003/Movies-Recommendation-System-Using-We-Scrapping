{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40f6c43c-60b7-488a-8af2-ccaffa552c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries for data manipulation and analysis\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "# Importing libraries for text processing and similarity calculations\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# Importing NLTK library for natural language processing tasks\n",
    "import nltk\n",
    "# Importing PorterStemmer for stemming words in text data\n",
    "from nltk.stem.porter import PorterStemmer as ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19684f0f-0d3b-498c-8b23-c9694d926ea6",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'movie_df.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Read the movie data from the 'movie_df.csv' file into a pandas DataFrame (redundant line)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmovie_df.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1706\u001b[0m     f,\n\u001b[0;32m   1707\u001b[0m     mode,\n\u001b[0;32m   1708\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1709\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1710\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1711\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1712\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1713\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1714\u001b[0m )\n\u001b[0;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    864\u001b[0m             handle,\n\u001b[0;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    866\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    867\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    869\u001b[0m         )\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'movie_df.csv'"
     ]
    }
   ],
   "source": [
    "# Read the movie data from the 'movie_df.csv' file into a pandas DataFrame (redundant line)\n",
    "df = pd.read_csv('movie_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5262b3c8-6981-45ef-b3b0-74605db17238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample 5 random rows from the DataFrame to inspect the data\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14852047-91cc-4b10-a72f-9d1c82b83a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting specific columns from the DataFrame 'df'\n",
    "df = df[[\"id\",\"title\",\"genre_ids\",\"overview\",\"popularity\",\"keywords\",\"cast\",\"crew\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48587120-b9e0-47d0-a167-061c92d27572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling 5 random rows from the DataFrame 'df'\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a186fa9b-d20f-42ab-99b2-7cc901ce2c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the dimensions of the DataFrame (number of rows, number of columns)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f449dd-f034-4d81-a3a9-7589f4c0295e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the total number of elements in the DataFrame (number of rows * number of columns)\n",
    "df.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ac0bd1-fb36-461d-9223-5ccc139e8b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary of the DataFrame, including column data types, non-null values, and memory usage\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdea7f9-95f9-4b56-a20b-05eba22a1bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in each column of the DataFrame and sum them up\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c44da2a-f56e-494a-834a-628d7383f3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with missing values from the DataFrame and update it in place\n",
    "df.dropna(inplace=True)\n",
    "# Check for missing values again after dropping rows and sum them up\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb01617-1909-4e10-80b0-0634126d379f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicated rows in the DataFrame and sum them up\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3165b53b-6653-4887-afcd-219ee00ae7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicated rows from the DataFrame and update it in place\n",
    "df.drop_duplicates(inplace=True)\n",
    "# Check for duplicated rows again after dropping duplicates and sum them up\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213051bc-2c0b-4d77-a903-c76c2c6c1429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df is your DataFrame and 'column_name' is the column you want to categorize\n",
    "# Find the 33rd and 66th percentiles\n",
    "percentiles = df['popularity'].quantile([0.33, 0.66])\n",
    "\n",
    "# Define a function to categorize values based on percentiles\n",
    "def categorize(value):\n",
    "    # If the value is less than or equal to the 33rd percentile, categorize as 'lessPopular'\n",
    "    if value <= percentiles[0.33]:\n",
    "        return 'lessPopular'\n",
    "    # If the value is less than or equal to the 66th percentile, categorize as 'mediumPopular'\n",
    "    elif value <= percentiles[0.66]:\n",
    "        return 'mediumPopular'\n",
    "    # Otherwise, categorize as 'Popular'\n",
    "    else:\n",
    "        return 'Popular'\n",
    "\n",
    "# Apply the categorization function to the column\n",
    "df['popularity'] = df['popularity'].apply(categorize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2deb0a50-0466-4ae5-ace5-462b92a4a066",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c2e7bf-fe8a-4b9a-b99f-cf5977431649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function named string_to_list that takes a string (col) as input\n",
    "def string_to_list(col):\n",
    "    # Split the input string into a list of words using space (\" \") as the separator\n",
    "    words_list = col.split(\" \")\n",
    "    # Return the resulting list of words\n",
    "    return words_list\n",
    "\n",
    "# Apply the string_to_list function to each element in the 'overview' column of the DataFrame (df),\n",
    "# converting each string into a list of words and updating the 'overview' column with the lists\n",
    "df['overview'] = df['overview'].apply(string_to_list)\n",
    "\n",
    "# Apply the string_to_list function to each element in the 'popularity' column of the DataFrame (df),\n",
    "# converting each string into a list of words and updating the 'popularity' column with the lists\n",
    "df['popularity'] = df['popularity'].apply(string_to_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241ae4e6-9163-47a0-848b-4d22f17678fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the changes\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd3f62d-74d9-4ec4-890e-65b6b4f3f402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any spaces in the 'keywords' column and update the DataFrame with the modified values\n",
    "df['keywords'] = df['keywords'].apply(lambda x: ''.join(x.split()))\n",
    "\n",
    "# Remove any spaces in the 'cast' column and update the DataFrame with the modified values\n",
    "df['cast'] = df['cast'].apply(lambda x: ''.join(x.split()))\n",
    "\n",
    "# Remove any spaces in the 'crew' column and update the DataFrame with the modified values\n",
    "df['crew'] = df['crew'].apply(lambda x: ''.join(x.split()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f80d525-0307-4cbd-8e76-e414cd85be34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the changes\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bcd6ed-c104-4d5a-b9af-68cfa1fc57c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "# Assuming 'column' contains the string representation of a list\n",
    "# It converts the string representation of a list to an actual list datatype.\n",
    "# imports the \"ast\" (Abstract Syntax Trees) module, which is used to safely \n",
    "# evaluate literal expressions from strings containing Python data types.\n",
    "df['genre_ids'] = df['genre_ids'].apply(ast.literal_eval)\n",
    "df['keywords'] = df['keywords'].apply(ast.literal_eval)\n",
    "df['cast'] = df['cast'].apply(ast.literal_eval)\n",
    "df['crew'] = df['crew'].apply(ast.literal_eval)\n",
    "\n",
    "# Now 'column' contains the list instead of the string representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e13a04-d714-4e21-9532-43ad15560ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d2e2b6-b0ae-476a-a08d-c840be30f293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a new column named 'tags' in the DataFrame 'df'. It concatenates the values from multiple \n",
    "# existing columns ('genre_ids', 'overview', 'popularity', 'keywords', 'cast', and 'crew') row-wise \n",
    "# and assigns the result to the 'tags' column.\n",
    "df['tags'] = df['genre_ids'] + df['overview'] + df['popularity'] + df['keywords'] + df['cast'] + df['crew'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51fdcf7-374a-4bc5-822d-12ac9802f84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking changes\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2077e46b-f1da-4a65-83bd-3d4d0003d9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a new DataFrame called 'movies_df' by selecting specific columns ('id', 'title', and 'tags') from the DataFrame 'df'.\n",
    "movies_df = df[['id','title','tags']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c293a48-2d44-4520-97f3-55e7a1ea90bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check changes\n",
    "movies_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38a4d87-3d19-400a-9176-a254ff0f8da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting a list into a string \n",
    "movies_df['tags'] = movies_df['tags'].apply(lambda x:\" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99decaa-7028-45f1-882d-f0b1521471fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting each words in lower words in tags column \n",
    "movies_df['tags'] = movies_df['tags'].apply(lambda x:x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376414f8-fb50-4f90-a6ec-5226117b0841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking changes\n",
    "movies_df['tags'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6016d8ed-6c77-46ec-9e65-d79e5799d116",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421f5a52-d71b-4cf3-ae5d-a1dc290dc528",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Create an instance of PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "\n",
    "# Define the stem function\n",
    "def stem(text):\n",
    "    y = []\n",
    "    for i in text.split():\n",
    "        y.append(ps.stem(i))  # Append the stemmed word to the list\n",
    "    return \" \".join(y)  # Join the stemmed words back into a single string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8207d0-c646-4a72-8686-92db209ddbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the stem function to the 'tags' column\n",
    "movies_df['tags'] = movies_df['tags'].apply(stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e104db6-fcd0-4b1a-bdd7-79e08601eb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a CountVectorizer object\n",
    "cv = CountVectorizer(max_features=8000, stop_words='english')\n",
    "\n",
    "# Fit the vectorizer to your list of strings and transform the data\n",
    "vectorized_data = cv.fit_transform(movies_df['tags'])\n",
    "\n",
    "# Now vectorized_data contains the Bag-of-Words (BoW) representation of your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f105ae2-9e95-472a-bd11-2a14d2905c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convertion a sparce matrix into a array\n",
    "vectorized_array = vectorized_data.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1258d115-4b66-4661-b232-1cca2d9593c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the array\n",
    "vectorized_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8c6102-725d-45f3-956d-6f8d7049b7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the dimensions of the DataFrame (number of rows, number of columns)\n",
    "vectorized_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19eb397-9349-4ced-9fb2-86c09f07ee03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the feature names from the CountVectorizer object.\n",
    "cv.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df68f58-19c2-4142-8339-d790ed8a38e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the cosine_similarity function from the sklearn library.\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Calculating cosine similarity between vectorized_array and itself.\n",
    "cosine_sim = cosine_similarity(vectorized_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa29f44c-8451-4f04-957a-fb72dc32e313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the chnages\n",
    "cosine_sim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2f5a02-efdd-401f-9791-51fbba21f44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function called recommend that takes a movie as input\n",
    "def recommend(movie):\n",
    "    # Find the index of the movie in the DataFrame\n",
    "    movie_id = movies_df[movies_df['title'] == movie].index[0]\n",
    "    # Get the cosine similarity scores for the movie\n",
    "    distance = cosine_sim[movie_id]\n",
    "    # Create a list of tuples containing movie indices and their cosine similarity scores, sorted by score\n",
    "    movies_list = sorted(list(enumerate(distance)), reverse=True, key=lambda x:x[1])[1:6]\n",
    "\n",
    "    # Iterate over the top 5 recommended movies and print their titles\n",
    "    for i in movies_list:\n",
    "        print(movies_df.iloc[i[0]].title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3406a551-78da-4407-b828-c741ec0d87df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommend similar movies to 'movie_name'.\n",
    "recommend('Dilwale Dulhania Le Jayenge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c65dda-8db3-4b08-9da6-309d00028d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df[movies_df['id'] == 19404]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305e9cc9-3730-492e-aaad-04d6b675a30b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa7f0fa-4d95-4677-ab63-68bc71b43444",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8f084b-29dc-4b6a-8c27-ad4c39d26984",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c31210a-aeab-4c4e-95d7-7fb5a243e513",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cf174e-f694-41b6-9ae3-5425166bacbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
